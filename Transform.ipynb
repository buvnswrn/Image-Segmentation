{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "    \n",
    "class default_layer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(default_layer, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3,1,1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)  \n",
    "    \n",
    "class up_layer(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(up_layer,self).__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.layer = default_layer(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layer(self.upsample(x))\n",
    "\n",
    "class recurrent_layer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(recurrent_layer, self).__init__()\n",
    "        self.layer = default_layer(channels, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x + self.layer(x))  \n",
    "    \n",
    "class recurrent_block(nn.Module):\n",
    "    def __init__(self,  in_channels, out_channels):\n",
    "        super(recurrent_block, self).__init__()\n",
    "        self.r2c = nn.Sequential(\n",
    "            recurrent_layer(out_channels),\n",
    "            recurrent_layer(out_channels)\n",
    "        )\n",
    "        self.conv1x1 = nn.Conv2d(in_channels,out_channels,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1x1(x)\n",
    "        return x + self.r2c(x)\n",
    "    \n",
    "class down_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(down_block, self).__init__()\n",
    "        self.r2c = recurrent_block(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r2c(x)\n",
    "        return self.maxpool(x), x\n",
    "    \n",
    "class up_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(up_block, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.up_layer = up_layer(in_channels, out_channels)\n",
    "        self.r2c = recurrent_block(in_channels,out_channels)\n",
    "\n",
    "    def forward(self, x, attachment):\n",
    "        x = self.up_layer(x)\n",
    "        \n",
    "        x = torch.cat((attachment,x),dim=1)\n",
    "        x = self.r2c( x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Segnet(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(Segnet, self).__init__()\n",
    "        \n",
    "        self.down_rcl1 = down_block(3, 64)\n",
    "        self.down_rcl2 = down_block(64, 128)\n",
    "        self.down_rcl3 = down_block(128, 256)\n",
    "        self.down_rcl4 = down_block(256, 512)\n",
    "        \n",
    "        self.down_rcl5 = recurrent_block(512, 1024)\n",
    "        \n",
    "        self.up_rcl1 = up_block(1024, 512)\n",
    "        self.up_rcl2 = up_block(512, 256)\n",
    "        self.up_rcl3 = up_block(256, 128)\n",
    "        self.up_rcl4 = up_block(128, 64)\n",
    "        self.conv1x1 = nn.Conv2d(64,classes,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, a = self.down_rcl1(x)\n",
    "        x, b = self.down_rcl2(x)\n",
    "        x, c = self.down_rcl3(x)\n",
    "        x, d = self.down_rcl4(x)\n",
    "        x = self.down_rcl5(x)\n",
    "        \n",
    "        x = self.up_rcl1(x, d)\n",
    "        x = self.up_rcl2(x, c)\n",
    "        x = self.up_rcl3(x, b)\n",
    "        x = self.up_rcl4(x, a)\n",
    "        x = self.conv1x1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nfrom PIL import Image\\n\\ndef removesuffix(content, suffix):\\n    if content.endswith(suffix):\\n        content = content[:-len(suffix)]\\n    return content\\n\\ndef findFiles(rootDir, suffix):\\n    files = []\\n    for r, d, f in os.walk(rootDir):\\n        for file in f:\\n            if suffix in file:\\n                files.append(removesuffix(str(file), suffix))\\n    return files\\n\\ndef substringBefore(string, char):\\n    return string[:string.index(char)]\\n\\ndataset = \"val\"\\n\\ninputRoot = \"/datasets/leftImg8bit/\" + dataset + \"/\"\\ntargetRoot = \"/datasets/gtFine/\" + dataset + \"/\"\\ninputSuffix = \\'_leftImg8bit.png\\'\\ntargetSuffix = \\'_gtFine_labelIds.png\\'\\n\\nreducedRoot = \"/datasets/cityscapes/medium/\" + dataset + \"/\"\\n\\n\\nos.makedirs(reducedRoot + \"input/\" )\\nos.makedirs(reducedRoot + \"target/\" )\\n\\nfiles = findFiles(inputRoot, inputSuffix)\\n#targetImages = findFiles(inputRoot, targetSuffix)\\n\\ni = 0;\\n\\ntargetSize = (512, 256)\\n\\nfor file in files:\\n    \\n    \\n    cityName = substringBefore(file, \"_\")\\n    \\n    input = Image.open(inputRoot + cityName + \"/\" + file + inputSuffix)\\n    target = Image.open(targetRoot + cityName + \"/\" + file + targetSuffix)\\n\\n    input = input.resize(targetSize)\\n    target = target.resize(targetSize, Image.NEAREST)\\n\\n    input.save(reducedRoot + \"input/\" + str(i).zfill(4) +  \".png\")\\n    target.save(reducedRoot + \"target/\" + str(i).zfill(4) +  \".png\")\\n    \\n    i += 1\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "from PIL import Image\n",
    "\n",
    "def removesuffix(content, suffix):\n",
    "    if content.endswith(suffix):\n",
    "        content = content[:-len(suffix)]\n",
    "    return content\n",
    "\n",
    "def findFiles(rootDir, suffix):\n",
    "    files = []\n",
    "    for r, d, f in os.walk(rootDir):\n",
    "        for file in f:\n",
    "            if suffix in file:\n",
    "                files.append(removesuffix(str(file), suffix))\n",
    "    return files\n",
    "\n",
    "def substringBefore(string, char):\n",
    "    return string[:string.index(char)]\n",
    "\n",
    "dataset = \"val\"\n",
    "\n",
    "inputRoot = \"/datasets/leftImg8bit/\" + dataset + \"/\"\n",
    "targetRoot = \"/datasets/gtFine/\" + dataset + \"/\"\n",
    "inputSuffix = '_leftImg8bit.png'\n",
    "targetSuffix = '_gtFine_labelIds.png'\n",
    "\n",
    "reducedRoot = \"/datasets/cityscapes/medium/\" + dataset + \"/\"\n",
    "\n",
    "\n",
    "os.makedirs(reducedRoot + \"input/\" )\n",
    "os.makedirs(reducedRoot + \"target/\" )\n",
    "\n",
    "files = findFiles(inputRoot, inputSuffix)\n",
    "#targetImages = findFiles(inputRoot, targetSuffix)\n",
    "\n",
    "i = 0;\n",
    "\n",
    "targetSize = (512, 256)\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    \n",
    "    cityName = substringBefore(file, \"_\")\n",
    "    \n",
    "    input = Image.open(inputRoot + cityName + \"/\" + file + inputSuffix)\n",
    "    target = Image.open(targetRoot + cityName + \"/\" + file + targetSuffix)\n",
    "\n",
    "    input = input.resize(targetSize)\n",
    "    target = target.resize(targetSize, Image.NEAREST)\n",
    "\n",
    "    input.save(reducedRoot + \"input/\" + str(i).zfill(4) +  \".png\")\n",
    "    target.save(reducedRoot + \"target/\" + str(i).zfill(4) +  \".png\")\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:7\")\n",
    "model = torch.load(\"/datasets/modelsWithoutNormalize/r2u_epoch_100.model\", map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "root = \"/datasets/cityscapes/medium/val/\"\n",
    "\n",
    "\n",
    "mapping = [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33]\n",
    "#mapping = [7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33]\n",
    "reduced_mapping = [7,8,11,12,13,17,19,20,21,22,23,24,25,26,27,28,31,32,33,]\n",
    "\n",
    "\n",
    "class cityscapes(data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.tf = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor()\n",
    "                #,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        return 500\n",
    "    def __getitem__(self, index):\n",
    "        name = str(index).zfill(4) + \".png\"\n",
    "        input = Image.open(root + \"input/\" + name )\n",
    "        target = Image.open(root + \"target/\" + name )\n",
    "        \n",
    "        inputTensor = self.tf(input)\n",
    "        \n",
    "        targetTensor = torch.from_numpy(np.array(target)).int()\n",
    "        \n",
    "        #targetResultTensor = torch.zeros((len(mapping), 256, 512), dtype=torch.float32)\n",
    "        \n",
    "        masks = []\n",
    "\n",
    "        for i in mapping:\n",
    "            masks.append(targetTensor == i)\n",
    "            \n",
    "        return inputTensor, torch.stack(masks).float()\n",
    "\n",
    "dst = cityscapes()\n",
    "trainloader = data.DataLoader(dst, batch_size = 1, num_workers = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 256, 512])\n",
      "torch.Size([1, 256, 512])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 22 is out of bounds for dimension 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-306-e7e52e1da260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mcolorImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mtargetImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargetIndices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargetIndices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargetIndices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 22 is out of bounds for dimension 0 with size 20"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "'''\n",
    "colors = torch.tensor([\n",
    "    [  0,  0,  0],\n",
    "    [111, 74,  0],\n",
    "    [ 81,  0, 81],\n",
    "    [128, 64,128],\n",
    "    [244, 35,232],\n",
    "    [250,170,160],\n",
    "    [230,150,140],\n",
    "    [ 70, 70, 70],\n",
    "    [102,102,156],\n",
    "    [190,153,153],\n",
    "    [180,165,180],\n",
    "    [150,100,100],\n",
    "    [150,120, 90],\n",
    "    [153,153,153],\n",
    "    [153,153,153],\n",
    "    [250,170, 30],\n",
    "    [220,220,  0],\n",
    "    [107,142, 35],\n",
    "    [152,251,152],\n",
    "    [ 70,130,180],\n",
    "    [220, 20, 60],\n",
    "    [255,  0,  0],\n",
    "    [  0,  0,142],\n",
    "    [  0,  0, 70],\n",
    "    [  0, 60,100],\n",
    "    [  0,  0, 90],\n",
    "    [  0,  0,110],\n",
    "    [  0, 80,100],\n",
    "    [  0,  0,230],\n",
    "    [119, 11, 32],\n",
    "    [  0,  0,  0]\n",
    "]) / 255\n",
    "'''\n",
    "\n",
    "colors = torch.tensor([\n",
    "    [128, 64,128],\n",
    "    [244, 35,232],\n",
    "    [ 70, 70, 70],\n",
    "    [102,102,156],\n",
    "    [190,153,153],\n",
    "    [153,153,153],\n",
    "    [250,170, 30],\n",
    "    [220,220,  0],\n",
    "    [107,142, 35],\n",
    "    [152,251,152],\n",
    "    [ 70,130,180],\n",
    "    [220, 20, 60],\n",
    "    [255,  0,  0],\n",
    "    [  0,  0,142],\n",
    "    [  0,  0, 70],\n",
    "    [  0, 60,100],\n",
    "    [  0, 80,100],\n",
    "    [  0,  0,230],\n",
    "    [119, 11, 32],\n",
    "    [0,0,0]\n",
    "]) / 255\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "model.train()\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(trainloader):\n",
    "        #if loss != None and i % 50 == 0:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        outputs = outputs.cpu()\n",
    "        targets = targets.cpu()\n",
    "\n",
    "        \n",
    "        targetValues, targetIndices = targets.max(dim=1)\n",
    "        values, indices = outputs.max(dim=1)\n",
    "\n",
    "        #targetIndices[targetValues < 0.1] = 30\n",
    "        #indices[values < 0.1] = 30\n",
    "        \n",
    "        #noValidate = targetValues < 0.1\n",
    "        #targetIndices[noValidate] = size\n",
    "        #indices[noValidate] = size\n",
    "       \n",
    "        \n",
    "        colorImage = torch.stack([colors[indices, 0 ], colors[indices, 1], colors[indices, 2]], dim=1)\n",
    "        targetImage = torch.stack([colors[targetIndices, 0 ], colors[targetIndices, 1], colors[targetIndices, 2]], dim=1)\n",
    "\n",
    "        clear_output(wait=False)\n",
    "        \n",
    "        \n",
    "        print(indices.unique())\n",
    "\n",
    "        print(\"-----\", torch.sum(torch.logical_and((targetIndices == 22), (indices == 22)))  )\n",
    "        print((targetIndices == indices).float().sum() / torch.prod(torch.tensor(list(targetIndices.size()))))\n",
    "        print(outputs.shape, targets.shape)\n",
    "        display(transforms.ToPILImage()( inputs[0] ))\n",
    "        display(transforms.ToPILImage()( targetImage[0] ))\n",
    "        display(transforms.ToPILImage()( colorImage[0] ))\n",
    "        display(transforms.ToPILImage()( (indices == 30).float() ))\n",
    "        sleep(5)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "size = len(mapping)\n",
    "\n",
    "dice = np.zeros(size)\n",
    "dice_count = np.zeros(size)\n",
    "jaccard = np.zeros(size)\n",
    "jaccard_count = np.zeros(size)\n",
    "confusion_matrix = np.zeros((size, size))\n",
    "\n",
    "model.train()\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(trainloader):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        outputs = outputs.cpu()\n",
    "        targets = targets.cpu()\n",
    "\n",
    "\n",
    "        targetValues, targetIndices = targets.max(dim=1)\n",
    "        values, indices = outputs.max(dim=1)\n",
    "\n",
    "        noValidate = targetValues < 0.1\n",
    "        targetIndices[noValidate] = size\n",
    "        indices[noValidate] = size\n",
    "        \n",
    "        flattenTarget = targetIndices.flatten()\n",
    "        flattenOutput = indices.flatten()\n",
    "        \n",
    "        confusion_matrix += sklearn.metrics.confusion_matrix(flattenTarget, flattenOutput, labels=range(size))\n",
    "        \n",
    "        for k in range(size):\n",
    "            targetIsClass = flattenTarget==k\n",
    "            outputIsClass = flattenOutput==k\n",
    "            occured = (torch.sum(outputIsClass) + torch.sum(targetIsClass))\n",
    "            if occured != 0:\n",
    "                dice_count[k] += 1\n",
    "                dice[k] += torch.sum(flattenOutput[targetIsClass]==k)*2.0 / occured\n",
    "            #else:\n",
    "            #    dice[k] += 1\n",
    "                \n",
    "            denominator = torch.sum(torch.logical_or(targetIsClass, outputIsClass))\n",
    "            \n",
    "            \n",
    "            if denominator != 0:\n",
    "                jaccard_count[k] += 1\n",
    "                jaccard[k] += torch.sum(torch.logical_and(targetIsClass, outputIsClass)) / denominator\n",
    "            #else:\n",
    "            #    jaccard[k] += 1\n",
    "         \n",
    "        \n",
    "dice /= dice_count \n",
    "jaccard /= jaccard_count  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SE</th>\n",
       "      <th>SP</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Dice</th>\n",
       "      <th>Jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>road</td>\n",
       "      <td>0.9855805011526195</td>\n",
       "      <td>0.9922825455464832</td>\n",
       "      <td>0.9897433078483191</td>\n",
       "      <td>0.9864523097237202</td>\n",
       "      <td>0.9412266845703126</td>\n",
       "      <td>0.9221177978515624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sidewalk</td>\n",
       "      <td>0.8932178516962564</td>\n",
       "      <td>0.9922510471660128</td>\n",
       "      <td>0.9871873022508881</td>\n",
       "      <td>0.876985929515681</td>\n",
       "      <td>0.6927998657226563</td>\n",
       "      <td>0.5960266723632812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>building</td>\n",
       "      <td>0.9282519736045934</td>\n",
       "      <td>0.980228278688879</td>\n",
       "      <td>0.9687473399315498</td>\n",
       "      <td>0.929185599266671</td>\n",
       "      <td>0.8467560424804688</td>\n",
       "      <td>0.765544189453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wall</td>\n",
       "      <td>0.505515611149414</td>\n",
       "      <td>0.9952158779712885</td>\n",
       "      <td>0.9918667714698922</td>\n",
       "      <td>0.4595059430550483</td>\n",
       "      <td>0.13047211911497997</td>\n",
       "      <td>0.09493608234309349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fence</td>\n",
       "      <td>0.4445445990094039</td>\n",
       "      <td>0.9968244592125416</td>\n",
       "      <td>0.992632144400986</td>\n",
       "      <td>0.47808130591743836</td>\n",
       "      <td>0.11173667488517341</td>\n",
       "      <td>0.0784496097774296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pole</td>\n",
       "      <td>0.5376012399712875</td>\n",
       "      <td>0.9983095826194798</td>\n",
       "      <td>0.9918814489321278</td>\n",
       "      <td>0.6488599248639118</td>\n",
       "      <td>0.535083251953125</td>\n",
       "      <td>0.3916888122558594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>traffic light</td>\n",
       "      <td>0.5339232764149804</td>\n",
       "      <td>0.999717078852113</td>\n",
       "      <td>0.998828798783373</td>\n",
       "      <td>0.6348680029400224</td>\n",
       "      <td>0.30728906588230087</td>\n",
       "      <td>0.22683875326545774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>traffic sign</td>\n",
       "      <td>0.680015884922561</td>\n",
       "      <td>0.9994750421846834</td>\n",
       "      <td>0.9975499805700889</td>\n",
       "      <td>0.7698555821423397</td>\n",
       "      <td>0.5736288464503733</td>\n",
       "      <td>0.4539547198214512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vegetation</td>\n",
       "      <td>0.9530504513977873</td>\n",
       "      <td>0.9830605871088663</td>\n",
       "      <td>0.9777901634129794</td>\n",
       "      <td>0.937780958606781</td>\n",
       "      <td>0.8748405013151302</td>\n",
       "      <td>0.8064182564347445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>terrain</td>\n",
       "      <td>0.6506491944895684</td>\n",
       "      <td>0.9978158699045977</td>\n",
       "      <td>0.9952056991380466</td>\n",
       "      <td>0.6711300530766846</td>\n",
       "      <td>0.24327417021816217</td>\n",
       "      <td>0.18421856407980317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sky</td>\n",
       "      <td>0.9654679596656552</td>\n",
       "      <td>0.9982468900422161</td>\n",
       "      <td>0.997127205842651</td>\n",
       "      <td>0.9582630583912337</td>\n",
       "      <td>0.8113247605620838</td>\n",
       "      <td>0.7687868837450371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>person</td>\n",
       "      <td>0.7791946176640933</td>\n",
       "      <td>0.9979123422143018</td>\n",
       "      <td>0.995154328020222</td>\n",
       "      <td>0.802191989383049</td>\n",
       "      <td>0.4457967657791941</td>\n",
       "      <td>0.35100955360814146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rider</td>\n",
       "      <td>0.4522181733083712</td>\n",
       "      <td>0.9991038909836885</td>\n",
       "      <td>0.9979439853443767</td>\n",
       "      <td>0.48266726137377336</td>\n",
       "      <td>0.24073754046930515</td>\n",
       "      <td>0.17572405911231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>car</td>\n",
       "      <td>0.9462441783001649</td>\n",
       "      <td>0.9955883009420763</td>\n",
       "      <td>0.9923491600928595</td>\n",
       "      <td>0.9419868639206755</td>\n",
       "      <td>0.8193727562784666</td>\n",
       "      <td>0.7507534876526126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>truck</td>\n",
       "      <td>0.168149042383112</td>\n",
       "      <td>0.9996623875704307</td>\n",
       "      <td>0.9974035959286138</td>\n",
       "      <td>0.2602736266899655</td>\n",
       "      <td>0.03721235905374799</td>\n",
       "      <td>0.02654246985912323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bus</td>\n",
       "      <td>0.07751004016064257</td>\n",
       "      <td>0.9994654045100536</td>\n",
       "      <td>0.9960064185180507</td>\n",
       "      <td>0.12712127082526153</td>\n",
       "      <td>0.033251013684628614</td>\n",
       "      <td>0.021497676621622115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train</td>\n",
       "      <td>0.6742462552531082</td>\n",
       "      <td>0.995018212451541</td>\n",
       "      <td>0.9946921297710305</td>\n",
       "      <td>0.20525261104401948</td>\n",
       "      <td>0.023304871312229764</td>\n",
       "      <td>0.018428147830192948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>motorcycle</td>\n",
       "      <td>0.0941293626707132</td>\n",
       "      <td>0.9999420977290282</td>\n",
       "      <td>0.9992648860399643</td>\n",
       "      <td>0.1606962153410241</td>\n",
       "      <td>0.041236924497704754</td>\n",
       "      <td>0.02887464197058427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>0.7839639064286523</td>\n",
       "      <td>0.9973319981126895</td>\n",
       "      <td>0.9958632600820427</td>\n",
       "      <td>0.7229189176353253</td>\n",
       "      <td>0.35793760930145135</td>\n",
       "      <td>0.27165841457734047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>**Average</td>\n",
       "      <td>0.6343933747180519</td>\n",
       "      <td>0.9956553628321563</td>\n",
       "      <td>0.9924862066514769</td>\n",
       "      <td>0.6344251275638224</td>\n",
       "      <td>0.42459378018586813</td>\n",
       "      <td>0.36491941013804075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name                   SE                  SP  \\\n",
       "0            road   0.9855805011526195  0.9922825455464832   \n",
       "1        sidewalk   0.8932178516962564  0.9922510471660128   \n",
       "2        building   0.9282519736045934   0.980228278688879   \n",
       "3            wall    0.505515611149414  0.9952158779712885   \n",
       "4           fence   0.4445445990094039  0.9968244592125416   \n",
       "5            pole   0.5376012399712875  0.9983095826194798   \n",
       "6   traffic light   0.5339232764149804   0.999717078852113   \n",
       "7    traffic sign    0.680015884922561  0.9994750421846834   \n",
       "8      vegetation   0.9530504513977873  0.9830605871088663   \n",
       "9         terrain   0.6506491944895684  0.9978158699045977   \n",
       "10            sky   0.9654679596656552  0.9982468900422161   \n",
       "11         person   0.7791946176640933  0.9979123422143018   \n",
       "12          rider   0.4522181733083712  0.9991038909836885   \n",
       "13            car   0.9462441783001649  0.9955883009420763   \n",
       "14          truck    0.168149042383112  0.9996623875704307   \n",
       "15            bus  0.07751004016064257  0.9994654045100536   \n",
       "16          train   0.6742462552531082   0.995018212451541   \n",
       "17     motorcycle   0.0941293626707132  0.9999420977290282   \n",
       "18        bicycle   0.7839639064286523  0.9973319981126895   \n",
       "19      **Average   0.6343933747180519  0.9956553628321563   \n",
       "\n",
       "                   ACC                   F1                  Dice  \\\n",
       "0   0.9897433078483191   0.9864523097237202    0.9412266845703126   \n",
       "1   0.9871873022508881    0.876985929515681    0.6927998657226563   \n",
       "2   0.9687473399315498    0.929185599266671    0.8467560424804688   \n",
       "3   0.9918667714698922   0.4595059430550483   0.13047211911497997   \n",
       "4    0.992632144400986  0.47808130591743836   0.11173667488517341   \n",
       "5   0.9918814489321278   0.6488599248639118     0.535083251953125   \n",
       "6    0.998828798783373   0.6348680029400224   0.30728906588230087   \n",
       "7   0.9975499805700889   0.7698555821423397    0.5736288464503733   \n",
       "8   0.9777901634129794    0.937780958606781    0.8748405013151302   \n",
       "9   0.9952056991380466   0.6711300530766846   0.24327417021816217   \n",
       "10   0.997127205842651   0.9582630583912337    0.8113247605620838   \n",
       "11   0.995154328020222    0.802191989383049    0.4457967657791941   \n",
       "12  0.9979439853443767  0.48266726137377336   0.24073754046930515   \n",
       "13  0.9923491600928595   0.9419868639206755    0.8193727562784666   \n",
       "14  0.9974035959286138   0.2602736266899655   0.03721235905374799   \n",
       "15  0.9960064185180507  0.12712127082526153  0.033251013684628614   \n",
       "16  0.9946921297710305  0.20525261104401948  0.023304871312229764   \n",
       "17  0.9992648860399643   0.1606962153410241  0.041236924497704754   \n",
       "18  0.9958632600820427   0.7229189176353253   0.35793760930145135   \n",
       "19  0.9924862066514769   0.6344251275638224   0.42459378018586813   \n",
       "\n",
       "                 Jaccard  \n",
       "0     0.9221177978515624  \n",
       "1     0.5960266723632812  \n",
       "2      0.765544189453125  \n",
       "3    0.09493608234309349  \n",
       "4     0.0784496097774296  \n",
       "5     0.3916888122558594  \n",
       "6    0.22683875326545774  \n",
       "7     0.4539547198214512  \n",
       "8     0.8064182564347445  \n",
       "9    0.18421856407980317  \n",
       "10    0.7687868837450371  \n",
       "11   0.35100955360814146  \n",
       "12   0.17572405911231226  \n",
       "13    0.7507534876526126  \n",
       "14   0.02654246985912323  \n",
       "15  0.021497676621622115  \n",
       "16  0.018428147830192948  \n",
       "17   0.02887464197058427  \n",
       "18   0.27165841457734047  \n",
       "19   0.36491941013804075  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "test = np.array(reduced_mapping)-4\n",
    "stripped_matrix = confusion_matrix[test][:, test]\n",
    "\n",
    "FP = stripped_matrix.sum(axis=0) - np.diag(stripped_matrix)  \n",
    "FN = stripped_matrix.sum(axis=1) - np.diag(stripped_matrix)\n",
    "TP = np.diag(stripped_matrix)\n",
    "TN = stripped_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "SE = np.nan_to_num(TP/(TP+FN))\n",
    "SP = np.nan_to_num(TN/(TN+FP))\n",
    "PC = np.nan_to_num(TP/(TP + FP))\n",
    "F1 = np.nan_to_num(2 * (PC * SE) / (PC + SE))\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "\n",
    "names = [\n",
    "    \"static\",\n",
    "    \"dynamic\",\n",
    "    \"ground\",\n",
    "    \"road\",\n",
    "    \"sidewalk\",\n",
    "    \"parking\",\n",
    "    \"rail track\",\n",
    "    \"building\",\n",
    "    \"wall\",\n",
    "    \"fence\",\n",
    "    \"guard rail\",\n",
    "    \"bridge\",\n",
    "    \"tunnel\",\n",
    "    \"pole\",\n",
    "    \"polegroup\",\n",
    "    \"traffic light\",\n",
    "    \"traffic sign\",\n",
    "    \"vegetation\",\n",
    "    \"terrain\",\n",
    "    \"sky\",\n",
    "    \"person\",\n",
    "    \"rider\",\n",
    "    \"car\",\n",
    "    \"truck\",\n",
    "    \"bus\",\n",
    "    \"caravan\",\n",
    "    \"trailer\",\n",
    "    \"train\",\n",
    "    \"motorcycle\",\n",
    "    \"bicycle\"\n",
    "]\n",
    "\n",
    "    \n",
    "def plot(table):\n",
    "    display(HTML(tabulate.tabulate(torch.tensor(table), tablefmt='html')))\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "names = np.array(names)[test]\n",
    "stripped_dice = dice[test]\n",
    "stripped_jaccard = jaccard[test]\n",
    "\n",
    "size = len(reduced_mapping)\n",
    "\n",
    "frame = [np.append(names, \"**Average\"), \n",
    "         np.append(SE, np.sum(SE) / size), \n",
    "         np.append(SP, np.sum(SP) / size), \n",
    "         np.append(ACC, np.sum(ACC) / size), \n",
    "         np.append(F1, np.sum(F1) / size), \n",
    "         np.append(stripped_dice, np.sum(stripped_dice) / size), \n",
    "         np.append(stripped_jaccard, np.sum(stripped_jaccard) / size)]\n",
    "\n",
    "\n",
    "pd.DataFrame(np.stack(frame, axis=1), columns=[\"Name\",\"SE\",\"SP\",\"ACC\",\"F1\",\"Dice\", \"Jaccard\"])\n",
    "\n",
    "#print(\"AC:\",precision / count)\n",
    "#print(\"SE:\",recall / count)\n",
    "#print(\"SE:\",recall / count)\n",
    "#print(\"DC:\",dice / count)\n",
    "#print(\"JS:\",jaccard / count)\n",
    "#print(\"JS:\",test / count)\n",
    "#print(\"Result:\",result / count)\n",
    "#print(\"Result:\",tnrs / 500)\n",
    "#print(accs / 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[255., 255.],\n",
       "         [  2.,   3.]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = colors[:, 0]\n",
    "g = colors[:, 1]\n",
    "b = colors[:, 2]\n",
    "\n",
    "values, indices = torch.max(a, 1)\n",
    "\n",
    "indices = torch.tensor([[[0,0.1],[2,3]]])\n",
    "\n",
    "indices[indices < 0.3] = 255\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[19, 19],\n",
       "         [ 0,  0]],\n",
       "\n",
       "        [[19,  0],\n",
       "         [ 0,  0]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[[-0.1,-0.1],[2,3]], [[-0.1,0.1],[2,3]]]])\n",
    "\n",
    "values, indices = a.max(dim=0)\n",
    "\n",
    "indices[values < 0.1] = 19\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], dtype=torch.int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[-1:0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
